Целью данного фреймворка является создание датасетов для обучения нейронных сетей.

Он состоит из следующих файлов:

* config.py  		- конфигурационный файл, который содержит все необходимые настройки
* create.py		- главный файл, в котором определён весь воркфлоу генерации датасета
* check.py		- файл, в котором определены проверочные действия, производимые перед созданием датасета для превентивного обнаружения неполных данных
* augmentation.py	- файл, в котором определяется модель аугментации данных
* rotation.py		- файл, в котором определены инструменты для аугментации данных методом поворота картинки на определённый угол
* mirror.py		- файл, в котором определены инструменты для аугментации данных методом горизонтального зеркального отображения картинки (относительно вертикальной оси X)
* merge.py		- файл, в котором определены инструменты для объединения всех (исходных и полученных в результате аугментации) данных
* crop.py		- файл, в котором определены инструменты для кропа (обрезания) картинок
* labels.py		- файл, в котором определены инструменты для создания результирующего файла с лейблами (ground truths) датасета
* mean.py		- файл, в котором определены инструменты для создания среднего изображения (mean image), которое необходимо для нормализации данных
* create_lmdb.py	- файл, в котором определены инструменты для создания баз данных (LMDB), необходимых для загрузки датасета в Caffe (или другие фреймворки для обучения нейронных сетей)
* microclasses.py	- файл, в котором определены инструменты для создания специального файла, необходимого для генерации датасета для задач классификации
* load.py		- файл, в котором собраны необходимые функции для загрузки данных всех предполагающихся типов
* newOrder.py		- файл, в котором определены функции получения нового порядка ландмарок при горизонтальном зеркальном отображении картинки
* util.py		- файл, в котором определены функции, находящие своё применение в разных классах и функциях данного фреймворка и не вошедшие в предыдущие файлы

Далее описаны правила использования фреймворка.

1. Определить тип задачи, для решения которой необходимо создать датасет.
В настоящий момент фреймворк поддерживает подготовку датасетов для следующих типов задач:
	* classification (обычная задача классификации или мультитаск)
	* landmarks
	* 3D
В config.py в Разделе "1. Main parameters" нужно указать правильный тип задачи для переменной 'mode'.

2. Определить тип фрейморка для обучения нейронных сетей, для которого предназначаются LMDBs, которые будут получены в результате построения датасета.
В настоящий момент фреймворк поддерживает подготовку датасетов для следующих фрейморков для обучения нейронных сетей:
	* caffe (Caffe BVLC и Caffe NVIDIA)
	* caffe2
В config.py в Разделе "1. Main parameters" нужно указать правильный тип фреймворка для переменной 'lmdb_mode'.

3. Указать полный путь к исходным данным, из которых будет генерироваться датасет.
В config.py в Разделе "2. Key paths and names" нужно указать для переменной 'main_path' полный путь к исходным данным.

N.B.:
i) В настоящий момент по умолчанию исходные данные должны быть приготовлены следующим образом:
	* для задач типа classification (обычная задача классификации или мультитаск):
		<main_path>
		    |_______superdir
				|________<img0>.jpg
				|________<img1>.jpg
				...
				|________<imgN>.jpg
				|________labels.csv
				|________landmarks.csv


	* для задач типа landmarks:
		<main_path>
		    |_______superdir
				|________<folder0>
                                            |________<img0>.jpg
                                            |________<img1>.jpg
                                            ...
                                            |________<imgN>.jpg
				            |________landmarks.csv
				|________<folder1>
                                            |________<img0>.jpg
                                            |________<img1>.jpg
                                            ...
                                            |________<imgN>.jpg
				            |________landmarks.csv
                                .
                                .
                                .
				|________<folderN>
                                            |________<img0>.jpg
                                            |________<img1>.jpg
                                            ...
                                            |________<imgN>.jpg
				            |________landmarks.csv

	* для задач типа 3D:
		<main_path>
		    |_______superdir
				|________bunch<0>
						|________<0>.obj
					                    |________<img0>.jpg
					                    |________<img1>.jpg
					                    ...
					                    |________<imgN>.jpg
						|________<1>.obj
					                    |________<img0>.jpg
					                    |________<img1>.jpg
					                    ...
					                    |________<imgN>.jpg
					        .
					        .
					        .
						|________<N>.obj
					                    |________<img0>.jpg
					                    |________<img1>.jpg
					                    ...
					                    |________<imgN>.jpg
				|________bunch<1>
						|________<0>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
						|________<1>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
				                .
				                .
				                .
						|________<N>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
                                ...
                                ...
                                ...
				|________bunch<N>
						|________<0>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
						|________<1>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
				                .
				                .
				                .
						|________<N>.obj
				                            |________<img0>.jpg
				                            |________<img1>.jpg
				                            ...
				                            |________<imgN>.jpg
				|________alphas
                                            |________<0>.alpha
                                            |________<1>.alpha
                                            ...
                                            |________<N>.alpha

ii) Все имена, указанные в выше приведённых схемах и не взятые в угловые кавычки '<' и '>', должны быть в структуре директорий. В частности, для задач всех типов важно, чтобы все сырые данные внутри 'main_path' были собраны внутри папки с именем 'superdir'. Часто сырые данные приходят таким образом, что главная папка имеет какое-то своё рандомное название. Чтобы унифицировать процесс создания датасета для различных задач, по дефолту входая папка, где хранятся сырые данные, называется 'superdir'. Нужно предварительно переименовать главную папку в нужную. Например, в случае задач типа classification в настоящее время приходят архивы, в которых главная папка называется 'export', соответственно, её нужно переимовать в 'superdir'.
iii) Во время генерации датасета будут создаваться вспомогательные файлы, поэтому перед созданием нового датасета рекомендуется создавать новую директорию main_path.

4. Определеить какие действия над данными должны быть произведены во время создания датасета.
В config.py в Разделе "3. Flags" нужно поставить 'True' для тех действий, которые нужно произвести и 'False' - для остальных.
N.B.:
i) В случае, если для параметра 'augmentation' указывается 'True', но необходимы дополнительные настройки аугментации, нужно определить их в Разделе '6. Augmentation parameters'.
ii) В случае задач типа classification нужно определить, нужно ли применять т.н. схему "main IF scheme augmentation", представляющую собой правила помикроклассовой аугментации датасета, исходя из принадлежности экземпляров микрокласса к классам для каждой задачи (см. Раздел "7.2 Functions for defining angles" файла config.py, где определяется эта схема аугментации). В config.py в Разделе "3.2 Other flags" нужно указать значение 'True' или 'False' для переменной 'run_main_IF_SCHEME_AUG'. В случае обычной классификации нужно указать 'False', в случае мультитаска -- 'True' или 'False' в зависимости от того, применима ли данная схема для исходных данных и требуется ли её применять в данном случае.

5. В случае задач типа classification или landmarks нужно определить, нужно ли применять аугментацию методом поворота картинки на определённый угол и если да, то указать политику выбора углов для аугментации данных методом поворота.

Если применять аугментацию методом поворота картинки не нужно:
- в Разделе '6. Augmentation parameters' изменить на 'False' значание ключа 'do' ключа 'rotation' словаря 'aug_params' для 'mode==classification' или 'mode==landmarks' соответсвенно).

Если применять аугментацию методом поворота картинки нужно:
- в Разделе '6. Augmentation parameters' изменить на 'True' значание ключа 'do' ключа 'rotation' словаря 'aug_params' для 'mode==classification' или 'mode==landmarks' соответсвенно) и, кроме того
- определить политику выбора углов для аугментации данных методом поворота:
	- для задач типа landmarks в config.py в Разделе "7.1 Angles defaults" нужно указать для переменной 'angles' список углов, на которые будут поворачиваться картинки.
	- для задач типа classification в config.py в Разделе "7.1 Angles defaults" нужно указать для переменной 'threshold' числовое значение (int), обозначающее количество картинок на микрокласс, которое будет решающим для применения схемы аугментации методом поворота картинки на определённый угол. Для выбора значения переменной 'threshold' рекомендуются следующие правила.

		В случае обычной классификации:
		- нужно указать число, равное желаемому количеству экземляров класса в результирующем датасете (например, если в исходном датасете 3 класса, в каждом по 1000 картинок, а на выходе хочется иметь 100К картинок по ~33К экземпляров на класс, то нужно указать 'threshold = 33000').

		В случае мультитаска:
		- нужно указать число, равное желаемому наименьшему количеству экземляров на микрокласс в результирующем датасете (например, если в исходном датасете 4,5К микроклассов, в 20% которых менее 20 картинок, а на выходе хочется иметь датасет, в котором в каждом микроклассе по крайней мере 20 картинок, то нужно указать 'threshold = 20'). При этом нужно проверить, применима ли к исходным данным т.н. схема "main IF scheme augmentation", устраивают ли её параметры для текущей задачи (для этого нужно идти в Раздел "7.2 Functions for defining angles") и требуется ли её применять в данном случае.

6. В случае задач типа classification или landmarks нужно определить, нужно ли применять аугментацию данных методом горизонтального зеркального отображения картинки (относительно вертикальной оси X).

Если применять аугментацию методом горизонтального зеркального отображения картинки не нужно:
- в Разделе '6. Augmentation parameters' изменить на 'False' значание ключа 'do' ключа 'mirror' словаря 'aug_params' для 'mode==classification' или 'mode==landmarks' соответсвенно).
' соответсвенно).

Если применять аугментацию методом горизонтального зеркального отображения картинки нужно:
- в Разделе '6. Augmentation parameters' изменить на 'True' значание ключа 'do' ключа 'mirror' словаря 'aug_params' для 'mode==classification' или 'mode==landmarks' соответсвенно).

7. Для задач типа classification нужно осуществить ряд дополнительных настроек.
7.1. Проверить, что задача, для которой создаётся датасет, есть в перечне tasks names. В Разделе '8.1 Tasks names list' функция get_tasks_names() возвращает два списка:
- tasks_names_in_labels_file -- все задачи, для которых присутствуют данные в файле 'labels.csv'
- tasks_names_to_work  	     -- задачи, которые нужно взять в качестве лейблов (собственное подмножество списка всех задач)
Если задача реализуется впервые или по какой-то причине её нет в этих перечнях, её нужно добавить, соблюдая при этом порядок. Т.е. если новая задача в файле 'labels.csv' идёт последним столбцом, то нужно добавить её название в конец обоих списков. При этом нужно сверить первый список, чтобы у нём были указаны в точности те задачи, которые присутствуют в выгруженном файле 'labels.csv'. А во втором списке оставить только те, которые нужно взять в качестве лейблов для обучения нейронной сети (остальные лучше не удалять, а закомментировать).

7.2. Если была добавлена новая задача, то нужно внести в Раздел '8.2 Tasks dictionary' все возможные значения лейблов для данной задачи. В функции get_tasks() определяется двухуровневый словарь tasks, на первом уровне которого ключами служат имена задач, а на втором -- лейблы для этих задач. В словарь нужно добавить новый ключ на первом уровне, который в точности соответствует названию новой задачи. Для него создать новый словарь, ключами которого служат имена лейблов, которые указаны в 'labels.csv'. Если количество и имена лейблов заранее известны, тогда добавляем в словарь tasks такую схему:
					<new_task_name>: {
					    <label0>:  np.array([0], dtype="int32"),
					    <label1>:  np.array([1], dtype="int32"),
					    ...
					    <labelN>:  np.array([N], dtype="int32")
					}
Если количество и имена лейблов заранее неизвестны (а равно если известны следующие дествия лучше проделать, чтобы удостовериться, что данные верны), то их следует извлечь из файла 'labels.csv'. Для этого надо загрузить в Python файл и по интересующей колонке получить все уникальные значения. Внимание! Нужно проверить, что числа, которые присвоены разным лейблам, различаются!